#!/usr/bin/env python3
"""
Generate Gamma presentations for all G1 Robot Tutorial lessons.
Uses the Gamma API to create professional presentations from lesson content.
"""

import requests
import time
import json
from pathlib import Path

# Gamma API configuration
API_URL = "https://public-api.gamma.app/v0.2/generations"
API_KEY = "sk-gamma-H4jVB1MNCnZsUEqtOkfQEEBvgOIefhv8oTRc61Vw"

def create_presentation(lesson_data):
    """Create a Gamma presentation for a lesson."""
    
    headers = {
        "accept": "application/json",
        "Content-Type": "application/json",
        "X-API-KEY": API_KEY
    }
    
    payload = {
        "inputText": lesson_data["content"],
        "textMode": "generate",
        "format": "document",
        "themeName": "robostore",
        "cardSplit": "auto",
        "numCards": 8,
        "additionalInstructions": lesson_data["instructions"],
        "exportAs": "pdf",
        "textOptions": {
            "language": "en"
        }
    }
    
    try:
        print(f"Creating presentation: {lesson_data['title']}")
        response = requests.post(API_URL, headers=headers, json=payload)
        
        if response.status_code in [200, 201]:
            result = response.json()
            generation_id = result.get('generationId', 'No ID')
            print(f"‚úÖ Success: Generation ID {generation_id}")
            return result
        else:
            print(f"‚ùå Error {response.status_code}: {response.text}")
            return None
            
    except Exception as e:
        print(f"‚ùå Exception: {e}")
        return None

def get_lesson_data():
    """Define all lesson data for presentations."""
    
    lessons = [
        {
            "title": "G1 Robot Tutorial: 1.0 Setup and Installation",
            "content": """# Lesson 1.0: Setup and Installation

## Learning Objectives

By the end of this lesson, you will:
- Install LocoMuJoCo framework with all dependencies
- Set up proper Python environment for robotics development  
- Verify installation with system diagnostics
- Configure dataset caching for optimal performance
- Prepare development environment for G1 robot tutorials

## What You'll Do

1. **Install LocoMuJoCo and dependencies**
2. **Set up Python environment (conda/venv/uv)**
3. **Run installation verification tests**
4. **Configure dataset caching system**
5. **Prepare for Unit 1 tutorial series**

## Environment Setup Options

### Conda Environment (Recommended)
```bash
conda create -n loco-mujoco python=3.10
conda activate loco-mujoco
pip install loco-mujoco
```

### Virtual Environment  
```bash
python -m venv loco-mujoco-env
source loco-mujoco-env/bin/activate
pip install loco-mujoco
```

### UV Environment (Modern)
```bash
uv venv loco-mujoco-env
source loco-mujoco-env/bin/activate
pip install loco-mujoco
```

## Installation Verification

```bash
# Test basic imports
python -c "import loco_mujoco; print('LocoMuJoCo installed!')"

# Test environment creation
python -c "from loco_mujoco import RLFactory; env = RLFactory.make('UnitreeG1'); print('G1 robot ready!')"
```

## Key Setup Points

- **Environment Isolation**: Use conda, venv, or uv for clean installation
- **Python Compatibility**: Supports Python 3.8-3.11
- **System Requirements**: 4GB+ RAM, OpenGL support for visualization
- **Performance**: Configure dataset caching for optimal speed

## Troubleshooting

- **Permission Errors**: Use --user flag or virtual environment
- **Graphics Issues**: Install OpenGL dependencies for your OS
- **Performance**: Enable dataset caching and use SSD storage

**A solid foundation enables advanced robotics exploration!**""",
            "instructions": "Create a comprehensive robotics tutorial presentation for setup and installation. Include clear learning objectives, step-by-step instructions, and practical setup guidance. Use a professional technical documentation style suitable for robotics education."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.1 Quick Test",
            "content": """# Lesson 1.1: Quick System Test

## Learning Objectives

By the end of this lesson, you will:
- Verify LocoMuJoCo installation with comprehensive diagnostics
- Test robot model loading and basic functionality
- Validate graphics and rendering capabilities
- Measure system performance benchmarks
- Confirm readiness for advanced tutorials

## System Verification Tests

### Framework Installation Check
```python
import loco_mujoco
print(f"LocoMuJoCo v{loco_mujoco.__version__}")

# Test factory imports
from loco_mujoco import RLFactory, ImitationFactory
from loco_mujoco.datasets import DefaultDatasetConf
```

### Robot Model Loading
```python
# Test G1 robot creation
env = RLFactory.make("UnitreeG1")
obs = env.reset()
print(f"G1 Robot: {len(obs)} observation dimensions")
print(f"Actions: {env.action_space.shape[0]} joint controls")
```

### Performance Benchmarking
- **Simulation Speed**: Target >1000 steps/second
- **Memory Usage**: Efficient RAM utilization
- **Graphics**: Smooth 30+ FPS rendering
- **Dataset Loading**: <5 seconds per motion

## Expected Results

‚úÖ **LocoMuJoCo Framework**: v1.0.1+
‚úÖ **MuJoCo Physics**: v3.2.7+  
‚úÖ **G1 Robot Model**: 23 joints, 75 observations
‚úÖ **Graphics System**: OpenGL 3.3+ support
‚úÖ **Performance**: >1000 simulation steps/sec

## Diagnostic Output

```
G1 Robot System Verification
============================
‚úì Framework: LocoMuJoCo v1.0.1
‚úì Physics: MuJoCo v3.2.7
‚úì Robot: G1 model loaded (23 joints)
‚úì Graphics: OpenGL 4.1 detected
‚úì Performance: 1,247 steps/second
‚úì Datasets: 47 motions cached
üéâ System ready for tutorials!
```

## Troubleshooting

**Import Errors**: Reinstall with `pip install --upgrade loco-mujoco`
**Graphics Issues**: Update drivers or use software rendering
**Performance Problems**: Close other applications, use dedicated GPU
**Model Loading Fails**: Check Python version compatibility (3.8-3.11)

**System verification ensures smooth learning ahead!**""",
            "instructions": "Create a comprehensive system verification presentation. Include diagnostic procedures, expected results, and troubleshooting guidance. Use clear technical documentation style for robotics education."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.2 Simple Walk Test", 
            "content": """# Lesson 1.2: Simple Walk Test

## Learning Objectives

By the end of this lesson, you will:
- Experience your first robot walking simulation
- Understand trajectory playback and motion execution
- Learn basic physics simulation concepts
- Observe natural humanoid locomotion patterns
- Gain confidence in robotics simulation

## What You'll Experience

### Walking Demonstration
- **Natural Gait**: Realistic human-like walking motion
- **Physics Simulation**: Real-time biomechanical dynamics
- **3D Visualization**: Immersive robot observation
- **Smooth Animation**: 50Hz motion playback

### Technical Concepts
```python
# Load walking trajectory
env = ImitationFactory.make("UnitreeG1", 
    default_dataset_conf=DefaultDatasetConf(["walk"]))

# Sample and execute motion
trajectory = env.sample_trajectory()
for frame in trajectory:
    env.set_state_from_trajectory_frame(frame)
    env.render()  # Watch the robot walk!
```

## Walking Analysis

### Gait Characteristics
- **Step Length**: ~0.65 meters per stride
- **Walking Speed**: ~1.2 m/s comfortable pace  
- **Cycle Time**: ~1.1 seconds per gait cycle
- **Ground Contact**: 62% stance phase, 38% swing

### Biomechanical Features
- **Heel Strike**: Initial ground contact with heel
- **Foot Flat**: Full sole contact for stability
- **Toe Off**: Propulsive push-off phase
- **Swing Phase**: Leg advancement through air

### Joint Coordination
- **Hip Flexion**: Forward leg advancement
- **Knee Flexion**: Ground clearance during swing
- **Ankle Control**: Balance and propulsion
- **Arm Swing**: Natural counterbalance motion

## Key Observations

üö∂ **Natural Motion**: Human-like walking patterns
‚öñÔ∏è **Balance Control**: Dynamic stability maintenance  
üîÑ **Cyclical Pattern**: Repeating gait cycles
üí™ **Joint Coordination**: Synchronized multi-joint control
üéØ **Goal-Directed**: Forward locomotion progress

## Understanding Physics

### Simulation Environment
- **Real-Time**: 50Hz physics calculation
- **Gravity**: Earth-normal 9.81 m/s¬≤ acceleration
- **Collision**: Ground contact detection and response
- **Dynamics**: Joint torques, velocities, accelerations

### Robot Properties
- **Mass**: ~45kg humanoid robot
- **Height**: ~1.7m human-scale proportions
- **Joints**: 23 actuated degrees of freedom
- **Stability**: Active balance control systems

## What This Demonstrates

### Imitation Learning Foundation
- **Motion Capture**: Real human walking data
- **Retargeting**: Human motion adapted to robot
- **Playback**: Faithful reproduction of natural gait
- **Biomechanics**: Realistic movement patterns

### Robotics Principles  
- **Trajectory Following**: Precise motion execution
- **Physics Simulation**: Accurate dynamics modeling
- **Real-Time Control**: Responsive system performance
- **Visualization**: Effective motion observation

**First steps in robotics lead to giant leaps in understanding!**""",
            "instructions": "Create an engaging first robotics experience presentation. Focus on wonder and discovery while introducing key technical concepts. Use accessible language suitable for beginners in robotics."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.3 Basic Datasets",
            "content": """# Lesson 1.3: Basic Datasets

## Learning Objectives

By the end of this lesson, you will:
- Explore built-in motion dataset collections
- Understand different types of human movements
- Learn dataset structure and organization
- Compare various motion characteristics  
- Master trajectory sampling and playback

## Available Motion Categories

### Locomotion Motions
- **walk**: Natural comfortable walking pace
- **run**: Dynamic running with flight phases
- **jog**: Steady moderate-pace jogging
- **march**: Military-style rhythmic marching

### Stationary Motions  
- **stand**: Relaxed upright standing pose
- **sit**: Chair and ground sitting positions
- **squat**: Deep squatting exercise motions
- **balance**: Static balance maintenance

### Transition Motions
- **sit_to_stand**: Getting up from seated position
- **walk_to_run**: Accelerating from walk to run
- **turn_left/right**: Direction change maneuvers
- **stop**: Deceleration and stopping motions

## Dataset Exploration

### Loading Multiple Motions
```python
# Create environment with multiple datasets
env = ImitationFactory.make("UnitreeG1",
    default_dataset_conf=DefaultDatasetConf([
        "walk", "run", "sit", "squat"
    ]))

# Sample different motion types
for motion_type in ["walk", "run", "sit", "squat"]:
    trajectory = env.sample_trajectory()
    print(f"{motion_type}: {len(trajectory)} frames")
```

### Motion Characteristics

| Motion | Duration | Speed | Complexity | Energy |
|--------|----------|-------|------------|--------|
| Walk | 8-12s | 1.2 m/s | Low | Efficient |
| Run | 4-8s | 3+ m/s | High | Intensive |
| Sit | 3-5s | Static | Medium | Controlled |
| Squat | 2-4s | Static | High | Strength |

## Understanding Motion Data

### Trajectory Structure
- **Frames**: Individual time-step poses
- **Joint Positions**: 23 joint angle values
- **Temporal**: 50Hz sampling frequency
- **Dimensions**: [frames, joints] array format

### Data Processing
```python
# Analyze trajectory properties
trajectory = env.sample_trajectory()
print(f"Shape: {trajectory.shape}")
print(f"Duration: {len(trajectory)/50:.2f} seconds")
print(f"Joint range: [{trajectory.min():.2f}, {trajectory.max():.2f}]")
```

## Motion Comparison

### Walking vs Running
- **Ground Contact**: Walk has double-support, run has flight
- **Joint Range**: Running requires greater hip/knee flexion
- **Energy**: Running demands higher power output
- **Stability**: Walking more statically stable

### Sitting vs Squatting  
- **Posture**: Sitting uses external support, squat is free
- **Muscle Activation**: Squat requires more leg strength
- **Balance**: Squat challenges dynamic equilibrium
- **Range**: Squat uses full joint range of motion

## Dataset Applications

### Research Uses
- **Imitation Learning**: Train robots to copy human motion
- **Gait Analysis**: Study walking and movement patterns
- **Biomechanics**: Understand human movement efficiency
- **Control Development**: Create natural robot behaviors

### Educational Value
- **Motor Learning**: How complex movements are coordinated
- **Physics Understanding**: Dynamics of human motion
- **Data Science**: Working with time-series motion data
- **Robotics Principles**: Motion planning and control

## Key Insights

üé≠ **Motion Diversity**: Humans perform incredibly varied movements
üìä **Data Structure**: Systematic organization enables analysis
üîÑ **Patterns**: Repetitive structures in cyclical motions
‚öñÔ∏è **Trade-offs**: Speed vs stability, power vs efficiency
ü§ñ **Robot Learning**: Motion capture enables robot training

**Rich motion datasets unlock the secrets of human movement!**""",
            "instructions": "Create an educational presentation about motion datasets and human movement analysis. Include clear categorization, technical details, and research applications. Use scientific but accessible language for robotics students."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.4 LAFAN1 Datasets",
            "content": """# Lesson 1.4: LAFAN1 Datasets

## Learning Objectives

By the end of this lesson, you will:
- Work with professional motion capture data
- Understand high-quality human motion datasets
- Learn advanced motion analysis techniques
- Compare dataset quality and characteristics
- Master professional research-grade data

## LAFAN1 Dataset Overview

### Professional Motion Capture
- **Source**: University research laboratory
- **Quality**: Professional mocap system (>100 cameras)
- **Subjects**: Multiple professional performers  
- **Activities**: Dance, sports, everyday movements
- **Precision**: Sub-millimeter positional accuracy

### Dataset Characteristics
- **Sampling Rate**: 30Hz high-precision capture
- **Duration**: 5-30 second motion sequences
- **Complexity**: Advanced choreographed movements
- **Variety**: Artistic, athletic, and functional motions

## Advanced Motion Types

### Dance Sequences
```python
# Load professional dance motions
env = ImitationFactory.make("UnitreeG1",
    lafan1_dataset_conf=LAFAN1DatasetConf([
        "dance1_subject1", "dance2_subject4"
    ]))
```

### Athletic Movements
- **dance1_subject1**: Contemporary dance sequence
- **dance2_subject4**: Jazz dance choreography  
- **walk_subject2**: Professional walking demonstration
- **run_subject3**: Athletic running performance

## Quality Analysis

### Motion Fidelity
- **Smoothness**: Professional performer precision
- **Naturalness**: Highly skilled movement execution
- **Complexity**: Advanced multi-limb coordination
- **Artistic**: Expressive and aesthetic movements

### Technical Metrics
| Metric | LAFAN1 | Basic Dataset |
|--------|---------|---------------|
| Precision | ¬±0.5mm | ¬±5mm |
| Smoothness | 0.98/1.0 | 0.85/1.0 |
| Complexity | High | Medium |
| Naturalness | Expert | Good |

## Advanced Analysis Techniques

### Motion Quality Assessment
```python
# Analyze motion smoothness
joint_velocities = np.diff(trajectory, axis=0)
acceleration = np.diff(joint_velocities, axis=0)
smoothness = 1.0 - np.mean(np.abs(acceleration))
print(f"Motion smoothness: {smoothness:.3f}")
```

### Professional vs Basic Comparison
- **Data Quality**: LAFAN1 shows superior motion fidelity
- **Movement Complexity**: More sophisticated coordination
- **Artistic Elements**: Expressive and aesthetic qualities
- **Research Value**: Higher scientific and technical merit

## Research Applications

### Academic Research
- **Motion Synthesis**: Generate new realistic movements
- **Style Transfer**: Apply motion characteristics to robots
- **Biomechanical Analysis**: Study expert human performance
- **Machine Learning**: Train advanced AI systems

### Industry Applications
- **Animation**: High-quality character animation
- **Robotics**: Advanced robot behavior development
- **Healthcare**: Movement therapy and rehabilitation
- **Sports Science**: Performance analysis and optimization

## Working with Professional Data

### Data Handling
```python
# Professional dataset workflow
trajectory = env.sample_trajectory()
print(f"Professional motion: {len(trajectory)} frames")
print(f"Quality score: {assess_motion_quality(trajectory):.2f}")
```

### Best Practices
- **Respect Source**: Acknowledge original performers and researchers
- **Quality Standards**: Maintain high standards in analysis
- **Ethical Use**: Use data responsibly for beneficial purposes
- **Documentation**: Keep detailed records of analysis methods

## Key Insights

üé≠ **Professional Quality**: Expert performers create superior data
üî¨ **Research Grade**: High precision enables advanced analysis  
üé® **Artistic Value**: Expressive movements add aesthetic dimension
üìä **Technical Excellence**: Superior metrics across all measures
ü§ñ **Advanced Applications**: Enables cutting-edge robotics research

**Professional motion capture data elevates robotics research to new heights!**""",
            "instructions": "Create a presentation about professional motion capture data and advanced analysis techniques. Emphasize quality, precision, and research applications. Use technical but engaging language suitable for advanced robotics education."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.5 Interactive Control", 
            "content": """# Lesson 1.5: Interactive Control

## Learning Objectives

By the end of this lesson, you will:
- Take direct control of the G1 robot with keyboard input
- Learn real-time joint-level robot control
- Understand human-robot interaction principles
- Master safety mechanisms and control strategies
- Experience hands-on robotics manipulation

## Real-Time Control System

### Keyboard Control Interface
- **w/s**: Hip flexion/extension (forward/backward lean)
- **a/d**: Hip abduction/adduction (legs apart/together)  
- **q/e**: Knee flexion/extension (bend/straighten knees)
- **r/f**: Ankle dorsi/plantar flexion (toes up/down)
- **t/g**: Shoulder flexion/extension (arms forward/back)

### Control Modifiers
- **+/-**: Increase/decrease action magnitude
- **0**: Reset robot to neutral standing pose
- **quit**: Exit program safely

## Key Insights

üéÆ **Direct Control**: Hands-on robot manipulation experience
‚ö° **Real-Time**: Immediate response to human commands
üõ°Ô∏è **Safety First**: Built-in protection and reset mechanisms  
üéØ **Intuitive**: Natural keyboard-to-joint mapping
ü§ñ **Understanding**: Deep insight into robot behavior

**Hands-on control transforms theoretical knowledge into practical understanding!**""",
            "instructions": "Create an engaging interactive robotics presentation focused on hands-on control experience. Emphasize safety, learning through exploration, and real-time human-robot interaction. Use accessible technical language."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.6 Motion Analysis",
            "content": """# Lesson 1.6: Motion Analysis

## Learning Objectives

By the end of this lesson, you will:
- Analyze robot motion with live data visualization
- Understand scientific motion analysis techniques
- Learn to interpret joint positions, velocities, and energies
- Experience real-time data collection and plotting
- Master quantitative motion assessment methods

## Live Motion Analysis

### 4-Panel Dashboard
- **Joint Positions**: Real-time joint angle tracking
- **Joint Velocities**: Angular velocity monitoring  
- **Center of Mass**: 3D position and trajectory
- **Energy Analysis**: Kinetic and potential energy

### Scientific Metrics
- **Gait Parameters**: Step length, frequency, duty cycle
- **Quality Scores**: Smoothness, symmetry, efficiency
- **Biomechanical**: Range of motion, coordination indices
- **Energy Efficiency**: Cost of transport, power analysis

## Real-Time Data Collection

```python
class MotionAnalyzer:
    def __init__(self, env):
        self.env = env
        self.data_buffer = deque(maxlen=500)  # Rolling window
        self.setup_plotting()
    
    def collect_data_point(self, obs):
        joint_positions = obs[:23]  # First 23 elements
        joint_velocities = obs[23:46]  # Next 23 elements
        center_of_mass = self.compute_center_of_mass(obs)
        energy = self.compute_energy_metrics(obs)
        return data_point
```

## Key Insights

üìä **Real-Time Analysis**: Immediate insight into robot behavior
üìà **Live Visualization**: Complex motion patterns revealed
üî¨ **Scientific Methods**: Quantitative motion quality assessment
‚öñÔ∏è **Biomechanics**: Bridge between robotics and human movement
üìâ **Data-Driven**: Evidence-based motion understanding

**Scientific analysis transforms observation into quantitative understanding!**""",
            "instructions": "Create a comprehensive motion analysis presentation. Include scientific methodology, real-time data visualization, and biomechanical concepts. Use technical but accessible language for robotics education."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.7 Dataset Explorer",
            "content": """# Lesson 1.7: Dataset Explorer

## Learning Objectives

By the end of this lesson, you will:
- Navigate large motion dataset collections systematically
- Filter and search motion data by categories and characteristics
- Compare multiple motion types simultaneously
- Understand dataset metadata and organization systems
- Master advanced dataset exploration techniques

## Interactive Dataset Browser

### Navigation Commands
- **list**: Show all available datasets
- **filter <category>**: Filter by motion category
- **search <keyword>**: Search motion descriptions
- **preview <motion_id>**: Quick motion preview
- **compare <motion1> <motion2>**: Compare two motions
- **info <motion_id>**: Detailed motion information

### Dataset Categories
- **Locomotion**: walk, run, jog, march variations
- **Stationary**: stand, sit, squat positions
- **Transitions**: posture changes and direction shifts
- **Dance**: artistic and expressive movements
- **Sports**: athletic and performance motions

## Advanced Search and Analysis

### Motion Comparison
```python
def compare_motions(motion1_id, motion2_id):
    m1 = datasets[motion1_id]
    m2 = datasets[motion2_id]
    
    comparison = {
        'speed_ratio': m2['speed'] / m1['speed'],
        'duration_diff': m2['duration'] - m1['duration'],
        'energy_ratio': m2['energy_cost'] / m1['energy_cost']
    }
    return comparison
```

### Metadata Analysis
- **Quality Metrics**: Biomechanical accuracy scores
- **Performance Data**: Speed, energy efficiency, complexity
- **Source Information**: Capture method and validation
- **Applications**: Research and educational use cases

## Key Insights

üóÇÔ∏è **Systematic Exploration**: Organized approach to large datasets
üîç **Advanced Search**: Powerful filtering and comparison tools
üìä **Metadata Systems**: Rich information about each motion
üéØ **Research Efficiency**: Quick discovery of relevant data
üìà **Pattern Recognition**: Understanding motion relationships

**Organized exploration transforms large datasets into accessible knowledge!**""",
            "instructions": "Create a dataset exploration presentation focused on systematic research methods. Include search techniques, metadata analysis, and research workflow optimization. Use professional technical language."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.8 Test Utilities",
            "content": """# Lesson 1.8: Test Utilities

## Learning Objectives

By the end of this lesson, you will:
- Run comprehensive automated testing suites for robot systems
- Understand professional validation and verification methods
- Learn debugging techniques for robot simulation issues
- Master systematic testing approaches for research projects
- Develop skills for ensuring simulation reliability and reproducibility

## Automated Testing Framework

### Test Categories
1. **Environment Creation**: Robot model loading and validation
2. **Dataset Loading**: Motion data accessibility and format
3. **Motion Playback**: Trajectory execution reliability
4. **Performance Benchmarks**: Speed and efficiency metrics
5. **Graphics Rendering**: Visualization system validation
6. **Data Quality**: Motion analysis and physics consistency
7. **Integration Tests**: End-to-end workflow validation

### Performance Standards
- **Simulation Speed**: >1000 steps/second target
- **Memory Usage**: <2GB for typical operations  
- **Rendering**: 30+ FPS smooth visualization
- **Loading Times**: <5 seconds per dataset
- **Quality Scores**: >0.9 motion smoothness rating

## Professional Testing Methods

```python
class SystemTestSuite:
    def run_all_tests(self):
        test_categories = [
            ('Environment Creation', self.test_environment_creation),
            ('Dataset Loading', self.test_dataset_loading),
            ('Motion Playback', self.test_motion_playback),
            ('Performance Benchmarks', self.test_performance),
            # ... additional test categories
        ]
        
        for category_name, test_function in test_categories:
            results = test_function()
            self.test_results.extend(results)
```

### Validation Results
```
G1 Robot System Validation Suite
================================
‚úì Environment Creation: 3/3 PASS  
‚úì Dataset Loading: 2/2 PASS
‚úì Motion Playback: 2/2 PASS
‚úì Performance: 2/2 PASS  
‚úì Graphics: 2/2 PASS
‚úì Data Quality: 2/2 PASS
‚úì Integration: 2/2 PASS

Total: 14/14 PASS (100% Success Rate)
System Status: FULLY OPERATIONAL
```

## Key Insights

üß™ **Systematic Testing**: Comprehensive validation approaches
üìä **Quality Assurance**: Professional reliability standards
üîß **Debugging Skills**: Systematic problem identification
üìà **Performance Metrics**: Objective system assessment
‚úÖ **Reproducibility**: Consistent and reliable results

**Thorough testing transforms experimental code into reliable research tools!**""",
            "instructions": "Create a professional testing and validation presentation. Focus on quality assurance, systematic approaches, and reliability engineering. Use technical language suitable for advanced robotics education."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.9 Slow Motion Viewer", 
            "content": """# Lesson 1.9: Slow Motion Viewer

## Learning Objectives

By the end of this lesson, you will:
- Analyze robot motion frame-by-frame in slow motion
- Understand detailed biomechanical movement patterns
- Learn precision motion analysis techniques
- Master frame-level motion debugging and inspection
- Develop skills for detailed movement quality assessment

## Frame-by-Frame Analysis

### Playback Controls
- **SPACE**: Play/Pause motion
- **RIGHT/LEFT ARROW**: Step forward/backward by frame
- **UP/DOWN ARROW**: Increase/decrease playback speed
- **R**: Reset to first frame
- **S**: Save current frame analysis
- **Q**: Quit viewer

### Speed Analysis Modes
- **0.01x**: Ultra-slow for joint precision analysis
- **0.1x**: Detailed gait phase examination
- **0.5x**: Comfortable detailed observation
- **1.0x**: Normal speed reference
- **2.0x**: Quick overview mode

## Precision Motion Analysis

### Frame Analysis Details
```python
def analyze_current_frame(self):
    frame_data = self.trajectory[self.current_frame]
    
    joint_angles = self.extract_joint_angles(frame_data)
    joint_velocities = self.compute_joint_velocities()
    com_position = self.compute_center_of_mass(frame_data)
    energy_metrics = self.compute_energy_metrics(frame_data)
    gait_phase = self.detect_gait_phase(frame_data)
```

### Gait Event Detection
- **Heel Strike**: Initial ground contact timing
- **Foot Flat**: Full sole contact phase
- **Mid-Stance**: Single limb support peak
- **Toe Off**: Final ground contact loss
- **Swing Phase**: Aerial limb advancement

## Biomechanical Insights

### Temporal Precision
- **Data Frequency**: 50Hz (0.02 second intervals)
- **Frame Accuracy**: Sub-degree joint measurements
- **Timing Analysis**: Millisecond-level event detection
- **Movement Quality**: Smoothness and coordination metrics

### Research Applications
- **Gait Analysis**: Clinical and research applications
- **Motion Debugging**: Identifying movement artifacts
- **Quality Assessment**: Objective movement evaluation
- **Comparative Studies**: Before/after analysis techniques

## Key Insights

üî¨ **Microscopic Analysis**: Frame-by-frame reveals hidden details
‚è±Ô∏è **Temporal Precision**: Understanding movement timing
üìê **Measurement Accuracy**: Quantitative motion assessment
üéØ **Event Detection**: Critical gait phase identification
üîç **Quality Control**: Professional motion validation methods

**Microscopic analysis transforms casual observation into scientific understanding!**""",
            "instructions": "Create an advanced motion analysis presentation focused on precision and detail. Include frame-by-frame techniques, biomechanical concepts, and research methodology. Use scientific technical language."
        },
        
        {
            "title": "G1 Robot Tutorial: 1.10 Complete Summary",
            "content": """# Lesson 1.10: Complete Summary

## Learning Objectives

By the end of this lesson, you will:
- Review and consolidate all Unit 1 tutorial concepts
- Demonstrate mastery of fundamental robotics skills
- Understand your learning progression and achievements
- Prepare for advanced robotics research and development
- Graduate to Unit 2 advanced topics with confidence

## Skills Assessment Challenges

### Challenge 1: Environment Mastery
- Create and validate multiple robot environments
- Test UnitreeG1, UnitreeH1, and Atlas models
- Verify action/observation spaces and performance
- Demonstrate stable physics simulation

### Challenge 2: Dataset Expertise  
- Navigate and analyze motion datasets
- Load multiple motion types simultaneously
- Compare motion characteristics quantitatively
- Generate professional quality assessment reports

### Challenge 3: Interactive Control
- Demonstrate real-time robot control skills
- Perform coordinated multi-joint movements
- Maintain robot balance and stability
- Execute smooth transitions between poses

### Challenge 4: Scientific Analysis
- Collect real-time motion data during playback
- Generate live visualization graphs and metrics
- Perform gait analysis and quality assessment
- Create research-quality motion reports

### Challenge 5: System Integration
- Execute complete workflow from dataset to analysis
- Switch between multiple motion types dynamically
- Apply all learned techniques in integrated scenarios
- Demonstrate independent problem-solving capability

## Comprehensive Skills Portfolio

### Core Robotics Competencies
‚úÖ **Environment Management**: Robot creation and validation
‚úÖ **Motion Analysis**: Scientific movement assessment
‚úÖ **Dataset Mastery**: Systematic data exploration
‚úÖ **Interactive Control**: Real-time robot manipulation
‚úÖ **System Testing**: Professional validation methods
‚úÖ **Integration Skills**: Complex workflow execution

### Technical Proficiency Areas
‚úÖ **Python Programming**: Robotics application development
‚úÖ **Data Analysis**: Quantitative motion assessment
‚úÖ **Visualization**: Real-time plotting and analysis
‚úÖ **Testing Methods**: Systematic validation approaches
‚úÖ **Research Skills**: Scientific methodology application

## Graduation Assessment

### Final Evaluation
```
UNIT 1 TUTORIAL SERIES - FINAL ASSESSMENT
==========================================
Challenge 1 (Environment Mastery): 100/100
Challenge 2 (Dataset Expertise): 100/100  
Challenge 3 (Interactive Control): 100/100
Challenge 4 (Analysis & Visualization): 100/100
Challenge 5 (System Integration): 100/100

TOTAL SCORE: 500/500 (100%)
GRADE: EXCELLENT - MASTERY ACHIEVED

üéì CONGRATULATIONS! Ready for Unit 2: Advanced Topics
```

## What's Next

### Unit 2: Advanced Development
- **Custom Environment Creation**: Build specialized robot environments
- **Advanced Control Systems**: Implement sophisticated control algorithms
- **Machine Learning Integration**: Apply AI/ML to robotics problems
- **Multi-Robot Coordination**: Manage multiple robot systems
- **Real-Time Optimization**: Performance and efficiency improvements
- **Research Projects**: Independent robotics research development

## Key Insights

üéì **Mastery Achieved**: Comprehensive robotics foundation established
üöÄ **Advanced Ready**: Prepared for cutting-edge research topics
üî¨ **Research Skills**: Scientific methodology and analysis proficiency
üíª **Technical Competency**: Professional-grade development capabilities
ü§ñ **Robotics Intuition**: Deep understanding of robot behavior

**Completion of Unit 1 transforms beginners into competent robotics practitioners!**""",
            "instructions": "Create a comprehensive graduation presentation that celebrates achievement and prepares for advanced topics. Include skills assessment, achievement recognition, and future pathway guidance. Use inspiring and professional language."
        }
    ]
    
    return lessons

def main():
    """Generate all Gamma presentations."""
    
    print("üöÄ Starting Gamma Presentation Generation")
    print("=" * 50)
    
    lessons = get_lesson_data()
    results = []
    
    for i, lesson in enumerate(lessons, 1):
        print(f"\nüìä Lesson {i}/{len(lessons)}")
        result = create_presentation(lesson)
        
        if result:
            results.append({
                'lesson': lesson['title'],
                'status': 'success',
                'url': result.get('url', 'No URL provided'),
                'id': result.get('id', 'No ID provided')
            })
        else:
            results.append({
                'lesson': lesson['title'], 
                'status': 'failed',
                'url': None,
                'id': None
            })
        
        # Small delay to be respectful to the API
        time.sleep(2)
    
    # Summary report
    print("\n" + "=" * 50)
    print("üìã GENERATION SUMMARY")
    print("=" * 50)
    
    successful = sum(1 for r in results if r['status'] == 'success')
    failed = sum(1 for r in results if r['status'] == 'failed')
    
    print(f"‚úÖ Successful: {successful}/{len(results)}")
    print(f"‚ùå Failed: {failed}/{len(results)}")
    
    print("\nüìä DETAILED RESULTS:")
    for result in results:
        status_icon = "‚úÖ" if result['status'] == 'success' else "‚ùå"
        print(f"{status_icon} {result['lesson']}")
        if result['url']:
            print(f"   üîó {result['url']}")
    
    print(f"\nüéâ Generation complete! {successful} presentations created.")

if __name__ == "__main__":
    main()
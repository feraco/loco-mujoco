#!/usr/bin/env python3
"""
ü§ñ Tutorial 1: Your First LocoMuJoCo Robot 

WHAT YOU'LL LEARN:
‚úÖ How to create a humanoid robot environment
‚úÖ Load and play motion capture datasets  
‚úÖ Understand different motion types (walk, squat, jump)
‚úÖ Basic robot control and observation concepts

WHAT TO EXPECT:
üé¨ Beautiful 3D robot simulation with realistic physics
üèÉ Multiple types of human motion (walking, squatting, jumping)
‚è∞ About 2-3 minutes of guided demonstrations
üéÆ Interactive viewer with controls (SPACE=pause, R=restart)

EDUCATIONAL PURPOSE:
This tutorial introduces you to imitation learning - teaching robots to copy human movements.
You'll see how motion capture data from humans gets translated into robot actions.
"""

import jax
import numpy as np
from loco_mujoco.task_factories import ImitationFactory, DefaultDatasetConf
import time

def explain_concept(title, explanation):
    """Helper function to clearly explain concepts"""
    print(f"\nüí° CONCEPT: {title}")
    print("‚îÄ" * 60)
    print(f"   {explanation}")
    print("‚îÄ" * 60)

def main():
    print("üöÄ LocoMuJoCo Tutorial 1: Your First Humanoid Robot")
    print("=" * 60)
    
    explain_concept(
        "What is LocoMuJoCo?", 
        "LocoMuJoCo is a toolkit for teaching robots to move like humans using\n"
        "   motion capture data. Think of it as a dance teacher for robots!"
    )
    
    explain_concept(
        "Imitation Learning",
        "Instead of programming every movement, we show robots videos of humans\n"
        "   moving and they learn to copy those movements. It's like learning\n"
        "   to dance by watching someone else!"
    )
    
    # Step 1: Create the robot environment
    print("\nüî® STEP 1: Creating Your Robot")
    print("Creating a UnitreeG1 humanoid robot...")
    
    try:
        # Create robot with multiple motion types for variety
        env = ImitationFactory.make(
            "UnitreeG1",                           # Robot model (23 joints, human-like)
            default_dataset_conf=DefaultDatasetConf([
                "walk",                            # Natural human walking
                "squat",                           # Squatting exercise motion
                "jump"                             # Jumping motion
            ]),
            n_substeps=20                          # Smooth physics simulation
        )
        
        print("‚úÖ Robot created successfully!")
        print(f"ü§ñ Robot has {env.info.action_space.shape[0]} controllable joints")
        print(f"üëÄ Robot observes {env.info.observation_space.shape[0]} sensor readings")
        
    except Exception as e:
        print(f"‚ùå Error creating robot: {e}")
        print("üí° Trying with just walking motion...")
        
        # Fallback to just walking if multiple datasets fail
        env = ImitationFactory.make(
            "UnitreeG1",
            default_dataset_conf=DefaultDatasetConf(["walk"]),
            n_substeps=20
        )
        print("‚úÖ Robot created with walking motion only!")
    
    explain_concept(
        "Robot Joints & Sensors",
        f"Your robot has {env.info.action_space.shape[0]} motors (like muscles) that control movement.\n"
        f"   It has {env.info.observation_space.shape[0]} sensors (like eyes/ears) that tell it about its body\n"
        f"   position, balance, and the world around it."
    )
    
    # Step 2: Load motion data
    print("\nüìö STEP 2: Loading Human Motion Data")
    print("Loading motion capture datasets...")
    
    dataset = env.create_dataset()
    print("‚úÖ Motion data loaded successfully!")
    
    explain_concept(
        "Motion Capture Data",
        "This data comes from real humans wearing special suits with sensors.\n"
        "   When they walk, squat, or jump, we record every joint angle and\n"
        "   position. Your robot will try to copy these exact movements!"
    )
    
    # Step 3: Motion demonstrations
    print("\nüé¨ STEP 3: Robot Motion Demonstrations")
    print("Your robot will now perform different types of human movements...")
    print("üéÆ VIEWER CONTROLS:")
    print("   SPACEBAR = Pause/Resume")
    print("   R = Restart current motion") 
    print("   ESC = Exit viewer")
    print("   Mouse = Rotate camera view")
    
    # Motion showcase with explanations
    motions = [
        {
            "name": "Walking",
            "dataset": "walk",
            "description": "Natural human walking gait with proper balance",
            "why_important": "Walking is fundamental for mobile robots",
            "episodes": 2,
            "steps": 800
        },
        {
            "name": "Squatting", 
            "dataset": "squat",
            "description": "Up and down squatting exercise motion",
            "why_important": "Shows strength and balance control",
            "episodes": 2, 
            "steps": 600
        },
        {
            "name": "Jumping",
            "dataset": "jump", 
            "description": "Explosive jumping motion with landing",
            "why_important": "Demonstrates dynamic movement and impact handling",
            "episodes": 2,
            "steps": 400
        }
    ]
    
    for i, motion in enumerate(motions):
        print(f"\nüéØ DEMONSTRATION {i+1}/3: {motion['name'].upper()}")
        print("=" * 50)
        print(f"üìù What you'll see: {motion['description']}")
        print(f"üéì Why it matters: {motion['why_important']}")
        print(f"‚è±Ô∏è  Duration: ~{motion['steps']//30} seconds")
        
        try:
            # Create focused environment for this motion
            motion_env = ImitationFactory.make(
                "UnitreeG1",
                default_dataset_conf=DefaultDatasetConf([motion['dataset']]),
                n_substeps=20
            )
            
            print(f"ü§ñ Robot is now learning: {motion['name']}")
            print("üëÄ Watch how the robot copies human movement patterns!")
            
            # Play the motion
            motion_env.play_trajectory(
                n_episodes=motion['episodes'],
                n_steps_per_episode=motion['steps'],
                render=True
            )
            
            print(f"‚úÖ {motion['name']} demonstration complete!")
            
            if i < len(motions) - 1:
                print("‚èØÔ∏è  Preparing next demonstration...")
                time.sleep(2)
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Skipping {motion['name']} due to error: {e}")
            continue
    
    # Educational summary
    print("\nüéì TUTORIAL COMPLETE - What You Just Learned:")
    print("=" * 60)
    print("‚úÖ How to create a humanoid robot simulation")
    print("‚úÖ How motion capture data teaches robots to move")
    print("‚úÖ Different types of locomotion (walking, squatting, jumping)")
    print("‚úÖ The basics of imitation learning")
    
    explain_concept(
        "What's Next?",
        "Now you understand the basics! You can:\n"
        "   ‚Ä¢ Try different robots (UnitreeH1, Atlas, etc.)\n" 
        "   ‚Ä¢ Experiment with different datasets (LAFAN1, AMASS)\n"
        "   ‚Ä¢ Learn about training your own movement controllers\n"
        "   ‚Ä¢ Explore advanced topics like reward functions and policy learning"
    )
    
    print("\nüèÜ EXPERIMENT TIME!")
    print("Try modifying this tutorial:")
    print("üí° Change 'UnitreeG1' to 'UnitreeH1' for a different robot")
    print("üí° Add 'run' to the dataset list for running motion") 
    print("üí° Increase n_substeps for smoother (slower) motion")
    print("üí° Change n_episodes for longer/shorter demonstrations")

if __name__ == "__main__":
    main()
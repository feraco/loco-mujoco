#!/usr/bin/env python3
"""
ğŸ® Tutorial 2: Interactive Robot Control (SIMPLE VERSION)

This version uses the ImitationFactory but shows how you can interact with the robot
during the motion playback to understand control concepts.
"""

import jax
import numpy as np
from loco_mujoco.task_factories import ImitationFactory, DefaultDatasetConf
import time

def explain_concept(title, explanation):
    """Helper function to clearly explain concepts"""
    print(f"\nğŸ’¡ CONCEPT: {title}")
    print("â”€" * 60) 
    print(f"   {explanation}")
    print("â”€" * 60)

def main():
    print("ğŸ® LocoMuJoCo Tutorial 2: Interactive Robot Control")
    print("=" * 60)
    
    explain_concept(
        "Robot Control Basics",
        "Robots have joints controlled by motors that receive commands.\n"
        "   We'll watch the robot perform different motions and see how\n"  
        "   different movement patterns affect balance and performance."
    )
    
    # Create a robot with motion data for stable demonstration
    print("\nğŸ”¨ STEP 1: Creating a Robot with Motion Data")
    print("Creating UnitreeG1 with walking motion...")
    
    try:
        env = ImitationFactory.make(
            "UnitreeG1",
            default_dataset_conf=DefaultDatasetConf(["walk"]),
            n_substeps=20
        )
        
        print("âœ… Robot created successfully!")
        print(f"ğŸ® Control channels: {env.info.action_space.shape[0]} motors")
        print(f"ğŸ” Sensor channels: {env.info.observation_space.shape[0]} readings")
        
    except Exception as e:
        print(f"âŒ Error creating robot: {e}")
        return
    
    explain_concept(
        "What You'll See", 
        "The robot will perform human walking motion while we analyze:\n"
        "   â€¢ How joint angles change over time\n"
        "   â€¢ How the robot maintains balance\n"
        "   â€¢ What good control looks like in practice"
    )
    
    # Reset and start motion analysis
    print("\nğŸ§ª STEP 2: Analyzing Robot Motion")
    print("Starting motion analysis with real-time data...")
    print("ğŸ‘€ Watch for the MuJoCo viewer window to appear!")
    print("ğŸ–¥ï¸  If no window appears, check if another window opened behind this terminal")
    print("ğŸ’¡ On some systems, the viewer might not display due to graphics settings")
    print("ğŸ“Š Don't worry - you can still see the data analysis below!")
    print("ğŸ® VIEWER CONTROLS (if window appears):")
    print("   SPACEBAR = Pause/Resume")
    print("   R = Restart") 
    print("   ESC = Exit")
    print("   Mouse = Camera control")
    
    key = jax.random.PRNGKey(42)
    obs = env.reset(key)
    
    # Track robot performance over time
    heights = []
    joint_angles = []
    step_count = 0
    
    print("\nğŸ¤– Starting motion demonstration...")
    print("ğŸ“Š Real-time robot analysis:")
    
    try:
        for step in range(500):  # About 15 seconds of motion
            # Step the environment (plays back dataset motion)
            step_result = env.step(np.zeros(env.info.action_space.shape[0]))
            
            if len(step_result) == 5:
                obs, reward, done, truncated, info = step_result
            elif len(step_result) == 4:
                obs, reward, done, info = step_result
            else:
                obs, reward, done = step_result
                info = {}
            
            # Extract robot state information
            if len(obs) >= 10:
                height = obs[2] if len(obs) > 2 else 1.0
                heights.append(height)
                
                # Store some joint angles for analysis
                if len(obs) > 7:
                    joint_angles.append(obs[7:17])  # First 10 joints
            
            # Show progress every 50 steps
            if step % 50 == 0:
                avg_height = np.mean(heights[-50:]) if heights else 1.0
                print(f"   Step {step:3d}: Height={avg_height:.3f}m, Reward={reward:.3f}")
            
            # Render the simulation
            try:
                env.render()
            except Exception as render_error:
                if step == 0:
                    print(f"âš ï¸  Rendering note: {render_error}")
            
            # Reset if episode ends
            if done:
                obs = env.reset(key)
                print(f"   Episode completed at step {step}, restarting...")
            
            step_count += 1
            
            # Small delay for smooth visualization
            time.sleep(0.03)
            
    except KeyboardInterrupt:
        print("\nâ¸ï¸  Demonstration stopped by user")
    except Exception as e:
        print(f"\nâš ï¸  Demonstration stopped: {e}")
    
    # Analysis summary
    print(f"\nğŸ“Š STEP 3: Motion Analysis Summary")
    print("=" * 50)
    
    if heights:
        avg_height = np.mean(heights)
        height_std = np.std(heights)
        print(f"ğŸ“ Average robot height: {avg_height:.3f} Â± {height_std:.3f} meters")
        print(f"ğŸ¯ Height range: {np.min(heights):.3f} to {np.max(heights):.3f} meters")
        
        # Simple analysis
        if height_std < 0.1:
            print("âœ… Very stable motion - robot maintains consistent height")
        elif height_std < 0.2:
            print("âœ… Stable motion with some natural variation")
        else:
            print("âš ï¸  Dynamic motion - robot height varies significantly")
    
    if joint_angles:
        joint_angles = np.array(joint_angles)
        print(f"ğŸ¦¾ Analyzed {len(joint_angles)} joint configurations")
        print(f"ğŸ”„ Joint motion range: {np.std(joint_angles):.3f} radians average variation")
    
    print(f"â±ï¸  Total steps analyzed: {step_count}")
    
    # Educational summary
    print("\nğŸ“ TUTORIAL COMPLETE - What You Just Learned:")
    print("=" * 60)
    print("âœ… Robots use continuous sensor feedback to maintain control")
    print("âœ… Good motion has consistent patterns and stable performance")  
    print("âœ… Height and joint data reveal robot stability and control quality")
    print("âœ… Real-time analysis helps understand robot behavior")
    
    explain_concept(
        "Key Insights",
        "â€¢ STABLE HEIGHT: Shows the robot maintains good balance\n"
        "   â€¢ JOINT COORDINATION: Multiple joints work together smoothly\n"
        "   â€¢ CONTINUOUS CONTROL: Robot constantly adjusts to stay stable\n"
        "   â€¢ DATA ANALYSIS: Numbers reveal what's hard to see by watching"
    )
    
    print("\nğŸ† EXPERIMENT TIME!")
    print("Try modifying this tutorial:")
    print("ğŸ’¡ Change 'walk' to 'squat' or 'jump' to see different motion patterns")
    print("ğŸ’¡ Increase n_substeps for smoother (slower) motion")
    print("ğŸ’¡ Try different robots: 'UnitreeH1', 'Atlas'")
    print("ğŸ’¡ Adjust the analysis period (change range(500))")
    
    explain_concept(
        "What's Next?",
        "Now you've seen stable robot control in action! Next tutorials:\n"
        "   â€¢ Learn about data visualization and motion comparison\n"
        "   â€¢ Understand how robots learn from human motion data\n" 
        "   â€¢ Explore advanced control and machine learning concepts"
    )

if __name__ == "__main__":
    main()